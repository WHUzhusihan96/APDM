data:
  dataset:
    name: CSC # choices are ['office', 'officehome', 'caltech-imagenet', 'visda2017']
    root_path: /data/sihan.zhu/myfile/dataset/CSC-allc/ # /path/to/dataset/root
    # 0:AID 1:CLRS 2:MLRSN 3:OPTIMAL-31
    source: 2 # source domain index
    target: 1 # target domain index
    n_share: 15 # number of classes to be shared
    n_source_private: 0 # number of classes in source private domain
    n_total: 15 # number of classes in total

  dataloader:
    class_balance: true #
    data_workers: 4 # how many workers to use for train dataloaders
    batch_size: 32 # batch_size for source domain and target domain respectively

model: resnet50 # choices=['resnet50', 'resnet18', 'resnet34', 'resnet101', 'vgg16', 'alexnet', 'densenet121']

train:
  min_step: 20000 # minimum steps to run. run epochs until it exceeds the minStep
  lr: 0.01 # learning rate for new layers. learning rate for finetune is 1/10 of lr
  weight_decay: 0.0005
  momentum: 0.9
  pcd_weight: 1.0 # choices=[0.50 0.75 1.0 1.25 1.50] best 1.0
  aux_weight: 0.1 # choices=[0.01, 0.05, 0.1, 0.5, 1.0] best 0.1

test:
  test_interval: 500 # interval of two continuous test phase
  test_only: False # test a given model and exit
  resume_file: '' # model to test

gpu_id: 0

log:
  root_dir: log/apdm/ # the log directory (log directory will be {root_dir}/{method}/time/)
  log_interval: 10 # steps to log scalars